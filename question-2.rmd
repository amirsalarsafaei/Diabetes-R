---
title: "Question 2"
output: html_document
---
## Loading Data and preparing environment

### Importing libraries and setting paths
```{r}
base_folder <- "/home/cafebazaar/R-Projects/diabet/" # change this:)

data_folder <- paste0(base_folder, "data/")
output_folder <- paste0(base_folder, "output/")

diabetes_012_path <- paste0(data_folder,"diabetes_012_health_indicators_BRFSS2015.csv")
diabetes_binary_5050_path <- paste0(data_folder, "diabetes_binary_5050split_health_indicators_BRFSS2015.csv")
diabetes_binary_path <- paste0(data_folder, "diabetes_binary_health_indicators_BRFSS2015.csv")

library(data.table)
library(ggplot2)
library(readxl)
library(corrplot)
```
### Loading datasets
```{r}
dt_012 <- data.table(read.csv(diabetes_012_path))
dt_5050 <- data.table(read.csv(diabetes_binary_5050_path))
dt <- data.table(read.csv(diabetes_binary_path))
```

# Question 2 answer

### Different ways...
To find the most important features(predictors) we can use various methods like using F-statistics/p-value in logistic regression(our problem is classification) or see estimate how many branches are created in tree methods (random forest, boosting, naive tree...) because of that predictor and comparing different features using that.

## My choice

As I was looking that the data my mind went to Tree based methods, we have lots of categorical features and that just tree based methods playground a lot of categorical features. As for Logistic Regression on the contrary this is a huge disadvantage.


**checking number of different values in each predictor(to see how many of them are categorical)**
```{r}
sapply(colnames(dt_5050), function(x) length(unique(dt_5050[[x]])))
```
Having this many categorical features and specially binary features confirms my theory about using tree based methods.

## Using boosting

So lets use gradient boosting on decision trees and fit our data.
We don't tune parameters because we only need feature importance.

[//]: # (```{r})

[//]: # (binary_columns <- c&#40;"HighBP"&#41;)

[//]: # (for &#40;column_name in categorical_columns&#41; {)

[//]: # (  dt_5050 <- dt_5050[, &#40;column_name&#41; := as.factor&#40;get&#40;column_name&#41;&#41;])

[//]: # (})

[//]: # (```)
```{r}
library('gbm')

model_gbm <- gbm(Diabetes_binary ~.,
                data = dt_5050,
                distribution = "multinomial",
                cv.folds = 10,
                shrinkage = .01,
                n.minobsinnode = 10,
                n.trees = 100/home/cafebazaar/R-Projects/diabet)
summary(model_gbm)


```

